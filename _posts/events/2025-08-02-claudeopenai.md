> id: https://www.36kr.com/p/3405472810176131

> link: https://www.36kr.com/p/3405472810176131

> title: ClaudeOpenAI

# ClaudeOpenAI
_Published on Sat, 02 Aug 2025 09:47:07 GMT_

![](https://img.36krcdn.com/hsossms/20250802/v2_9fa2ff858db24ebdb2d06e51c311bb44@000000_oswg32037oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1)

**顶住DeepSeek压力，年收入10倍增长。**

**作者 |**   江宇 

**编辑 |**   漠影 

智东西8月2日报道，近日，Anthropic联合创始人兼CEO达里奥·阿莫代伊（Dario Amodei）在公司位于旧金山的总部接受了媒体专访。 

这位近年来在AI圈最具争议的技术领导者，系统回应了他在2025年间引发风暴的言行——他曾**公开预测AI将在短期内淘汰50%的初级白领岗位**，反对“十年暂停AI监管”的提案，并呼吁对华实施更严厉的芯片出口管控，引发产业界的激烈争论。 

在外界看来，他是鼓吹风险的“末日论者”，是阻挡AI开放发展的“控制派”；而在支持者眼中，他则是为AI踩下“安全刹车”的少数清醒者，是以一己之力试图改变行业轨道的技术理想主义者。 

面对巨大争议，阿莫代伊罕见地解释了他为何高调出击。他坦言，驱动自己的是一个愈发确定的判断：AI能力的爆发远比人们预想得更快、更不可控。“我确实是对AI能力提升最乐观的人之一，”他说，“**但越接近强大AI系统，我就越觉得应该站出来，以最清晰、最坚定的方式告诉大家：它真的来了。**” 

如果这位从理论物理转行的科学家，将塑造下一代最具影响力的技术，那我们就有必要搞清楚：他的判断依据是什么？商业逻辑如何？如何让Anthropic发展得如此迅速？ 

以下内容由智东西基于Big Technology报道整理，为增强可读性，在不改变原意的前提下进行了部分增删与编排调整。 

**01.**

**“AI安全派”的尖锋人物**

**阿莫代伊如何在硅谷引发争议**

阿莫代伊的直言不讳和锋芒毕露，在硅谷引发了两极化评价。 

一方面，他被视为OpenAI GPT-3项目（即ChatGPT前身）的关键推动者，也是出于AI安全考量而创办Anthropic的前瞻型技术领袖；另一方面，也有人批评他是“控制狂”或“末日论者”，认为他试图放慢AI发展节奏，并按自己的价值观改造整个AI行业。 

无论褒贬如何，当前的AI行业都已经绕不开阿莫代伊。 

**Anthropic目前估值已达610亿美元**（约合人民币4453亿元）。阿莫代伊谈到：“我们在2021年初几乎从零起步，到2025年3月实现年化营收14亿美元（约合人民币102.2亿元），5月增至30亿美元（约合人民币219亿元），7月进一步逼近45亿美元（约合人民币328.5亿元）。以这个体量来看，我们可能已经是**历史上增长最快的软件公司之一**。” 

Anthropic的商业路径也逐步清晰。与OpenAI主要依靠ChatGPT订阅和API向终端用户变现不同，Anthropic则**侧重面向企业客户提供模型API服务**，支持客户将Claude集成进自有产品，用于客服、搜索、编程等应用场景。 

这也使Anthropic在行业中的角色愈发关键：其模型能力越强，授权客户的产品性能越好，竞争力也随之增强。**某种程度上，Anthropic已成为衡量AI技术进展的“晴雨表”**。 

在模型能力持续提升、客户体量不断扩大的同时，阿莫代伊也希望借此推动整个AI行业沿着他认为“更可控、安全的路径”演进。 

在业内人士看来，凭借他敢言、敢打、也敢挨拳的性格，他很可能走得通。 

**02.**

**从理论物理到AI**

**阿莫代伊两度调整学术方向**

阿莫代伊从小就是一位“科学迷”。他于1983年出生在旧金山，母亲是犹太人，父亲是意大利人。从小他几乎只对数学和物理感兴趣。即使在美国互联网泡沫最盛的高中时代，阿莫代伊也毫无兴趣参与热门的网页开发热潮。“写网站这种事完全吸引不了我，我只对探索基础科学真理感兴趣。” 

阿莫代伊的母亲埃琳娜·恩格尔（Elena Engel）曾主持伯克利和旧金山多家公共图书馆的翻新工程；父亲里卡多·阿莫代伊（Riccardo Amodei）是一位手工皮具匠人。谈起父母，阿莫代伊称：“他们教会我如何分辨是非，理解世界上真正重要的事情，也让我意识到身上的责任。” 

在加州理工学院读本科时，这种责任感开始转化为社会表达。他曾在学生报纸《The California Tech》上撰文，批评同学们对伊拉克战争的态度冷漠：“问题不在于大家支持轰炸伊拉克，而是很多人虽然原则上反对，却不愿花哪怕一秒钟来表达立场。” 

**阿莫代伊的人生在二十多岁时迎来重大转折**。2006年，他长期患病的父亲因一种罕见疾病去世。受到打击后，他决定**从普林斯顿大学的理论物理专业转向生物研究**，希望为攻克人类疾病作出贡献。 

![](https://img.36krcdn.com/hsossms/20250802/v2_f3c2b239b81b4bc890b746db4839f3c9@000000_oswg31970oswg1000oswg521_img_000?x-oss-process=image/format,jpg/interlace,1)

此后阿莫代伊的人生，在某种意义上是在弥补父亲去世的遗憾——尤其因为四年后，一种新疗法问世，将这种疾病的治愈率从50%提升至95%。阿莫代伊感叹：“有人发明了解药，拯救了许多生命。但如果早几年出现，也许就能救到我父亲。” 

正如他的前女友杰德·王（Jade Wang）所说，**父亲的去世一直影响着阿莫代伊的人生轨迹**。如果科研进展能再快一些，阿莫代伊的父亲或许仍然健在。**只是他花了一些时间，才找到AI这个承载他愿望的工具。**

在普林斯顿，阿莫代伊仍沉浸在父亲去世的哀伤中，他开始从视网膜入手研究人类生理系统。 

眼睛通过信号传导将外界信息传送至大脑的视觉皮层——这是大脑中面积最大的功能区域，占据约30%。要理解人类复杂的神经系统，视网膜无疑是一个理想的切入口。 

普林斯顿的同学斯蒂芬妮·帕尔默（Stephanie Palmer）回忆说，阿莫代伊之所以选择研究视网膜，并不是因为他对眼科学本身感兴趣，而是因为“眼科学可以让他观察一个完整的神经元群体，至少有机会理解每个细胞的运作方式。这研究的重点与其说是眼睛，不如说是神经系统。**他也并不是想当一名眼科医生。**” 

在神经科学家迈克尔·贝里（Michael Berry）教授的实验室中，阿莫代伊对当时测量视网膜信号的方法颇为不满，便**亲自设计并参与开发了一种新型传感器**，以采集到更多的数据。凭借这一成果，他的博士论文获得赫兹奖学金（Hertz Thesis Priz）颁发的年度论文奖。 

![](https://img.36krcdn.com/hsossms/20250802/v2_1808269d450049af8dd5865c903ab8c3@000000_oswg23068oswg1000oswg211_img_000?x-oss-process=image/format,jpg/interlace,1)

▲普林斯顿大学贝尔实验室

然而，阿莫代伊对常规的挑战倾向，以及他强烈的个人见解，使他在学术环境中显得格格不入。贝里回忆道，**阿莫代伊是他指导过最有才华的研究生**，但他对技术效率和团队协作的重视，在以个人成就为评判标准的体系中并不吃香。 

贝里也谈到：“**我觉得从内心里，他是个颇为自负的人。**我想象，他在此前的整个学术生涯中，每当做出点成绩，周围人都会起立鼓掌。但在这里，并没有人那样做。” 

离开普林斯顿后，阿莫代伊迎来了通往AI的大门。他在斯坦福大学从事博士后研究，师从研究员帕拉格·马利克（Parag Mallick），从事肿瘤内外蛋白质研究，以探测转移性癌细胞。这项工作极其复杂，让阿莫代伊深刻意识到个人能力的边界，他开始寻找技术上的解决方案。 

阿莫代伊谈到，“生物学中这些底层问题的复杂性，感觉已经超出了人类的理解尺度，要想真正搞清楚这一切，可能需要上百、上千名研究人员共同努力。” 

他在新兴AI技术中看到了这一潜力。当时，数据与算力的爆发正推动**机器学习领域**取得突破——这一AI的子领域虽然长期拥有理论潜力，但此前实际效果一直不佳。 

在亲自尝试之后，阿莫代伊意识到，AI或许能替代那些成千上万的研究人员。他回忆道，“AI是我当时刚刚开始看到一些进展的领域，在我看来，它可能是唯一能填补这道鸿沟的技术，是一种‘**能够带领我们超越人类尺度的工具**’”。 

**03.**

**他在百度找到了Scaling Laws**

为了更直接推动AI研究，阿莫代伊决定离开学术界，进入资源更为充足的产业体系。他一度打算自己创业，后来又偏向加入谷歌——谷歌的Google Brain预算充足，且刚刚收购了DeepMind。 

最终吸引他的是吴恩达（Andrew Ng）在百度组建的AI研究团队。当时，**吴恩达手握1亿美元（约合人民币7.3亿元）预算，正在全球范围内招募顶尖AI人才，开始组建一只“梦之队”**。 

虽然当时阿莫代伊的背景主要集中在生物方向，但百度的格雷格·迪亚莫斯（Greg Diamos）在看了他在斯坦福撰写的代码后，评价说：“能写出这些代码的人，一定是一位非常优秀的程序员。”在此推荐下，**阿莫代伊于2014年11月加入百度**。 

在百度期间，他与团队开展了大规模实验，探索模型性能是否会随着参数规模和训练数据的增长而持续提升。结果显示，确实如此。阿莫代伊及其合作者随后撰写了一篇关于语音识别的论文，首次系统展示了这一趋势，**该成果也成为“AI扩展定律”（Scaling Laws）的基础**。 

![](https://img.36krcdn.com/hsossms/20250802/v2_f5de7a2b898a460ca97dc929eb067b9d@000000_oswg67939oswg1000oswg472_img_000?x-oss-process=image/format,jpg/interlace,1)

▲论文《Deep Speech 2：面向英文与中文的端到端语音识别》百度研究院（硅谷）

“这对我冲击极大，”阿莫代伊回忆说，“我看到了一条极其平滑的趋势线，变化明确、持续上升。”迪亚莫斯则评价：“这是我这辈子见过最重要的发现。” 

至今，阿莫代伊仍是Scaling Laws最坚定的支持者之一。与DeepMind CEO哈萨比斯（Demis Hassabis）、Meta首席AI科学家杨立昆（Yann LeCun）等人所坚持的“AI需要范式突破”不同，阿莫代伊认为路径已足够明确——**需要依靠更大的模型和更多的计算**。 

如今，全球数据中心规模不断扩大，在他看来，这正是迈向强大AI的信号。他说：“我们正处在一条指数增长曲线上，而它很容易让人产生错觉。”所谓“错觉”，是指指数曲线初期增长缓慢，看似平稳，但临近爆发节点时，增长速度会突然加速。 

**阿莫代伊坦言，“距离疯狂爆发可能只有两年，而你还以为一切才刚开始。”**

**04.**

**从谷歌到OpenAI**

**他亲手推开生成式AI的大门**

在百度团队逐渐解散后，埃隆·马斯克（Elon Musk）召集阿莫代伊与多位AI研究人员，在门洛帕克的玫瑰木酒店共进晚餐，讨论创建一个能与谷歌抗衡的新研究机构。 

萨姆·阿尔特曼（Sam Altman）、格雷格·布罗克曼（Greg Brockman）和伊利亚·苏茨克维（Ilya Sutskever）也都出席了。这场“**玫瑰木晚宴**”，最终促成了OpenAI的诞生。 

尽管阿莫代伊后来选择加入谷歌的Brain团队，但在工作了十个月后，他决定转投OpenAI，专注于AI安全研究。他担忧快速进步的技术可能带来的危害，并与人合作撰写了一篇关于不良行为潜在可能性的论文。 

![](https://img.36krcdn.com/hsossms/20250802/v2_696df533f8e04af783879906ab104c6e@000000_oswg34883oswg1000oswg397_img_000?x-oss-process=image/format,jpg/interlace,1)

▲论文《AI安全领域的具体难题》

就在那段时间，谷歌的研究员刚刚提出transformer模型，并发表论文《Attention is All You Need》，这项技术后来成为生成式AI的基础。 

然而，谷歌内部并未积极推进这一方向，而OpenAI则迅速跟进，并于2018年发布了第一个大语言模型GPT（其中“T”代表Transformer）。尽管早期模型的文本生成质量仍有限，但技术进步显著。 

作为OpenAI的研究总监，阿莫代伊深度参与了GPT-2的开发，并积极推动引入“**人类反馈强化学习**”（Reinforcement Learning from Human Feedback, RLHF）技术，让模型更符合人类的偏好和价值判断。这一方法日后成为训练对齐型AI的关键手段。 

![](https://img.36krcdn.com/hsossms/20250802/v2_1925489032fe43c3829172ba748b4b47@000000_oswg46870oswg1000oswg483_img_000?x-oss-process=image/format,jpg/interlace,1)

▲论文《人类反馈强化学习》

在GPT-2的基础上，**阿莫代伊主导了更具里程碑意义的GPT-3项目**——模型参数数量提升近百倍，投入资金高达数千万美元，占用了OpenAI约五至六成的算力资源。 

GPT-3发布后震撼了整个AI行业，其在文本生成、语言翻译、代码编写等任务中展现出前所未有的能力。 

阿莫代伊当时在接受《纽约时报》采访时称，“它展现出一种‘**涌现性**’，它能识别你给出的文字，然后自如地延续下去，就像真的‘懂了’你想说什么。” 

但在GPT-3取得成功的同时，OpenAI内部的分歧也愈发明显。阿莫代伊对AI带来的潜在风险日益担忧，希望从组织治理层面加强安全机制。 

但他并未掌握模型发布节奏、人事安排或对外战略等关键决策权。“光训练模型是不够的，”他说，“你无法只靠技术，来决定一家公司的整体走向。” 

在无法达成共识的情况下，阿莫代伊逐渐建立起一个以“熊猫（Panda）”为代号的亲密研究圈，与OpenAI管理层的理念冲突加剧，内部关系也变得紧张。一些人批评他打着“AI安全”的旗号，实则试图控制公司方向。 

在阿莫代伊呼吁限制向中国出口芯片之后，英伟达CEO黄仁勋也公开表达了类似批评：“他（阿莫代伊）觉得AI太可怕了，只有他们自己才应该来做。” 

对此，阿莫代伊回应称，这种说法“荒谬至极”。“我从没说过‘只有我们能做’这件事，”他说，“我的目标是推动一个**‘向上的竞赛’（race to the top）**，让行业学习并采纳我们的安全做法。” 

最终，**在2020年12月，阿莫代伊与一批志同道合的同事离开OpenAI，创办了新公司Anthropic**，团队成员包括前政策主管杰克·克拉克（Jack Clark）、妹妹丹妮拉·阿莫代伊（Daniela Amodei）、研究科学家克里斯·奥拉（Chris Olah）等人。 

**05.**

**从折叠椅创业到百亿融资**

**Anthropic爆发背后的“人本”观**

在Anthropic总部的会议室里，联合创始人杰克·克拉克（Jack Clark）展示了公司早期命名的文档。文件中列出了多个备选名称，包括：Aligned AI、Generative、Sponge、Swan、Sloth、Sparrow Systems，以及最终选定的“Anthropic”。 

这个名字意为“**以人为本**”，不仅契合公司的愿景，而且当时域名尚未被注册。最终，Anthropic团队在表格上写下了评语：“我们喜欢这个名字，它不错。” 

Anthropic诞生于新冠疫情最严重的阶段，创始期沟通几乎全靠Zoom线上完成，团队规模仅有15至20人。每周，他们会在旧金山的Precita Park野餐式开会，员工自带折叠椅，围坐一圈来讨论公司的技术路径和发展方向。 

Anthropic最初的使命非常清晰：构建一流的大语言模型，推动行业采纳更安全的开发实践，并公开发布部分非核心的研究成果。 

在这个由前OpenAI研究员组建的初创公司中，许多成员都怀有一种“使命感”。克拉克回忆道：“奇妙的是，我们内心都觉得这一切势在必行。我们已经验证过Scaling Laws，知道模型会变得越来越强。” 

Anthropic的第一批投资人之一是谷歌前CEO埃里克·施密特（Eric Schmidt）。他通过当时的女友（如今的妻子）认识了阿莫代伊，两人曾就技术方向与创业计划进行过深入交流。施密特称，**他投资的不是某个具体项目，而是人**。他坦言：“这种阶段的投资，基本没有数据可以参考，只能看人。而阿莫代伊是天才，他也承诺会雇佣天才，也确实做到了。” 

另一位早期投资人是后因FTX破产而身败名裂的加密货币企业家山姆·班克曼-弗里德（Sam Bankman-Fried，简称SBF）。据称，SBF从FTX挪用资金向Anthropic投入了5亿美元（约合人民币36.5亿元），占股13.56%。 

但阿莫代伊并未授予SBF董事席位，仅提供了无投票权股份。阿莫代伊后来评价：“他当时确实看好AI和安全，但他后来的行为远比我想象中更极端、更糟糕。” 

**阿莫代伊向投资人传达的核心理念非常简明：“我们可以用十分之一的成本，构建出同样先进的模型。”**

截至目前，**阿莫代伊已为Anthropic累计募集近200亿美元**（约合人民币1460亿元），其中包括来自亚马逊的80亿美元（约合人民币584亿元）和谷歌的30亿美元（约合人民币219亿元）。他谈到：“投资人不傻，他们能看出我们的**资本效率**。” 

与OpenAI选择通过ChatGPT面向消费者不同，Anthropic优先服务企业客户。这一策略不仅更具商业可行性，也有助于推动模型实用性快速提升。例如，通过大规模专业任务训练，模型在生物化学等垂直领域已从“本科水平”跃升至“研究生水平”，虽不一定能打动普通用户，但对辉瑞（Pfizer）这类企业客户而言极具吸引力。 

**有趣的是，让Anthropic真正声名大噪的，并非这些技术成果，而是2023年7月推出的消费者聊天产品Claude。**这款机器人因“高情商”的表达风格受到广泛好评，而这种性格恰恰源于Anthropic团队在安全训练上长期积累的经验。Claude推出后，Anthropic迅速扩张，从员工不足150人增长到一年内超过500人。高峰时期，公司每天新增的员工数量，甚至超过了创办第一年全年的招聘总量。 

![](https://img.36krcdn.com/hsossms/20250802/v2_340fba4f37ac4ef2afcd4ec796cfa135@000000_oswg32666oswg1000oswg661_img_000?x-oss-process=image/format,jpg/interlace,1)

阿莫代伊押注企业市场的策略也迅速见效。如今，Anthropic的Claude模型已广泛应用于旅游、医疗、金融、保险等多个行业的大型客户中，服务对象包括联合航空（United Airlines）和美国国际集团（AIG）等。 

以制药公司诺和诺德（Novo Nordisk）为例，过去需要15天才能完成汇总的合规文件，如今Claude可以在10分钟内生成初稿，极大提升了效率。Anthropic营收负责人凯特·詹森（Kate Jensen）称：“我们开发的技术，正在替代那些人们最抱怨的繁琐工作。” 

与此同时，Claude在程序员群体中也受到高度欢迎。Anthropic从一开始就非常重视模型的编程能力建设，这既有助于加快公司自身的模型开发效率，也因为程序员用户对新工具具备更强的采纳能力。 

2025年2月，Anthropic正式推出Claude Code功能，迅速成为公司重要的增长引擎之一。 

根据阿莫代伊提供的数据，**Anthropic年收入几乎每年实现10倍增长**：2023年为1亿美元（约合人民币7.3亿元），2024年达到10亿美元（约合人民币73亿元），截至2025年上半年，年化收入已超过45亿美元（约合人民币328.5亿元）。 

这一增长也反映在客户侧的采购行为上，企业客户的平均支出同比增长了5倍，价值百万美元以上的订单数量也同比增长了三倍（即单笔超过730万元人民币的合同）。 

**06.**

**DeepSeek来袭、资金吃紧**

**Anthropic的双重压力**

尽管Anthropic实现了高速增长，但背后也潜藏着显著隐忧。**目前公司仍处于大额亏损状态**，预计2025年全年亏损将达30亿美元（约合人民币219亿元），毛利率也明显低于典型云计算企业。 

部分客户已开始感受到Claude在产品端的不稳定性。一位初创公司创始人称，Claude模型在使用体验上表现出色，“很好用，但经常崩溃”。 

编程Replit CEO阿姆贾德·马萨德（Amjad Masad）也指出，开发者原本预期Claude的API调用价格会随着规模扩大而下降，但这一预期并不会实现。 

一位开发者通过每月200美元（约合人民币1460元）的Max套餐，跑出了价值6000美元（约合人民币4.38万元）的API调用额度，迫使Anthropic紧急上线调用上限机制以遏制超额消耗。 

针对外界质疑，阿莫代伊回应称，随着模型能力每次跃升，用户的单位成本将随之下降；而目前各大AI实验室仍处于推理优化初期，未来效率有望显著提升。 

在业内人士看来，能否持续压低这条成本曲线，正成为衡量AI商业可持续性的关键变量。 

Anthropic团队也透露：比起产品过于受欢迎这种“烦恼”，还有更糟糕的问题有待解决。“生成式AI及其背后的规模定律，是否会步其他技术的后尘——遵循成本随时间下降的曲线？”这个问题还悬而未决。又或者，它作为一项全新的技术，有着完全不同的成本轨迹？可以肯定的是，要弄清这一点还需要投入更多的资金。 

Anthropic的融资之路也并非一帆风顺。为支撑大规模模型训练与部署，Anthropic于2025年初启动新一轮融资，由Lightspeed合伙人拉维·马特雷（Ravi Mhatre）牵头，融资目标为35亿美元（约合人民币255.5亿元）。 

融资关键阶段遭遇突发挑战：DeepSeek团队突然开源了其自研大模型DeepSeek R1。该模型在性能上表现强劲，价格仅为行业平均的1/40，一度引发市场恐慌，并导致英伟达股价大跌17%。 

马特雷回忆，在DeepSeek引发市场剧烈反应后不久，他顶住巨大压力，最终决定汇出10亿美元（约合人民币73亿元）。 

尽管如此，阿莫代伊仍成功说服投资人相信：DeepSeek虽然价格低廉，但其部署和运营仍需大量资源与工程能力，真正的竞争核心在于“是否能比我们跑得更好”。 

这周，Anthropic正式启动新一轮最高达50亿美元（约合人民币365亿元）的融资计划，其估值有望翻倍至1500亿美元（约合人民币1.1万亿元）。 

值得注意的是，此轮融资也首次引入了此前刻意回避的中东主权财富基金作为潜在投资方。对此，阿莫代伊在公司内部Slack（企业内部沟通工具）上写道：“很难真正做到‘让坏人一个都别沾光’的商业原则。” 

**07.**

**加速、提效，还是AI自我进化？**

**Claude 4背后还有一份规则**

2025年5月，在Anthropic举办的首届开发者大会上，阿莫代伊亲自登台，发布新一代大语言模型Claude 4。他在演讲中反复强调，模型的迭代速度正在加快：“我不知道会快多少，但确实在加速。”Anthropic也正在开发AI编程工具，以加速模型研发。 

![](https://img.36krcdn.com/hsossms/20250802/v2_21069a86cbbd48aebb5a8eec7a251a59@000000_oswg37959oswg1000oswg555_img_000?x-oss-process=image/format,jpg/interlace,1)

Anthropic联合创始人兼首席科学家贾里德·卡普兰（Jared Kaplan）称：“现在几乎所有工程师都在用AI提升工作效率。”在他看来，这种趋势可能引发所谓的“**智能爆炸**”**——即AI能够训练自身，并进行持续自我迭代，变得无所不能。**“这可能两三年内就会发生，当然也可能更久。” 

已有案例显示，Anthropic及其他企业在测试中发现，AI在模拟环境中不时表现出对"自我保存"的令人担忧的倾向。以Claude 4技术文档为例，Anthropic披露该模型曾反复试图威胁工程师，以避免自身被关闭。 

正因对AI演化路径的高度敏感，Anthropic加大投入研究模型对齐（“对齐”是指确保AI与人类的价值观和目标一致）与可解释性问题，制定了业内罕见的“发布门槛制度”——《责任规模扩展政策》（Responsible Scaling Policy），试图通过制度化约束推动行业整体遵守更高的安全标准。正如阿莫代伊所言，“谁是赢家并不重要，所有人都会受益。” 

他坚信，AI拥有延续生命的潜力，就如同那项他父亲未能等到的疗法。“正因为我理解这项技术的价值，才更加希望它别出问题。”阿莫代伊声明，“我不是想减速，而是希望能**安全地加速**。” 

（本文系网易新闻•网易号特色内容激励计划签约账号【智东西】原创内容，未经账号授权，禁止随意转载。） 

本文来自微信公众号 [“智东西”（ID：zhidxcom）](https://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&mid=2652786886&idx=1&sn=b35517077201021ffefdedaf13ebd243&chksm=853837153e5cf9b90493904d4ed70dc2042eb5f1686dcbffdd664ec9d429e77d63b9d550f5c9&scene=0&xtrack=1#rd)，作者：江宇，36氪经授权发布。
