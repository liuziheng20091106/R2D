> id: https://www.36kr.com/p/3426660861447555

> link: https://www.36kr.com/p/3426660861447555

> title: Genie 3SoraAI

# Genie 3SoraAI
_Published on Sun, 17 Aug 2025 08:40:00 GMT_

Genie 3是有史以来最先进的世界模型之一。

仅通过文本，它能够实时生成完全互动、高度一致的世界。

它不仅是DeepMind积累的结晶，还是通向AGI和具身智能体的关键一步。

但Genie 3是如何构建的？未来的世界模型又是什么样？

刚刚，谷歌DeepMind的研究科学家Jack Parker-Holder和研究总监Shlomi Fruchter，在a16z的访谈中，分享了他们的观点。

![](https://img.36krcdn.com/hsossms/20250817/v2_8ab74f9b34ee452ea3d0dfdce0bc8017@5579416_oswg325119oswg686oswg386_img_000?x-oss-process=image/format,jpg/interlace,1)

谷歌DeepMind的研究科学家Jack Parker-Holder和研究总监Shlomi Fruchter

这次对话提供了对Genie 3的第一手洞察。

主持人Justine Moore发推表示：「**Genie 3在网络上引发热潮**」。

![](https://img.36krcdn.com/hsossms/20250817/v2_886d8978386248fd8e222596ed1af0e4@5579416_oswg186051oswg1080oswg577_img_000?x-oss-process=image/format,jpg/interlace,1)

主持人Justine Moore发文

他总结了深入探讨的要点：

**Genie3是由两个DeepMind项目（Veo 2和Genie 2）合作完成的成果。**

**实时、互动的世界模型有很多潜在应用**。

**但应用并不是推动研究的主要动力——它们是从用户使用模型的过程中自然涌现出来的。**

**Genie 3可以保留最长达一分钟的空间记忆。**

**物理规律是模型的「自然产物」，并会随着训练数据的规模和深度而不断提升。**

**目前还没有一个「终极模型」能够同时具备Veo 3和Genie 3的所有能力。**

### **Genie 3：AI新魔法**

如果说LLM的原生图像编辑功能，「动动嘴PS」是「言出法随」，那Genie 3这次的新特性叫什么？

只需输入文本提示，Genie 3即可生成动态世界。用户可以实时进行探索，每秒高达24帧，分辨率为720p。

十多年来，谷歌DeepMind一直致力于模拟环境的研究。

Genie 3是他们最新最强的「世界模型」，是通向通用人工智能（AGI）的关键一步，因为它能让AI智能体在无限丰富的模拟环境中进行训练。

去年，他们推出了首批基础世界模型Genie 1和Genie 2，它们能为智能体生成全新的环境。此外，他们还通过Veo 2和Veo 3等视频生成模型，不断提升对直观物理的理解能力。

这些模型在世界模拟的不同能力上都取得了进展。Genie 3是谷歌首个支持实时交互的世界模型，同时提升了一致性和真实感。

![](https://img.36krcdn.com/hsossms/20250817/v2_4d039d607dfc4fa3a91b33eac0f08c06@5579416_oswg86835oswg1080oswg478_img_000?x-oss-process=image/format,jpg/interlace,1)

Genie 3在多个方面实现突破

在生成视频时长、世界一致性、内容的多样性、特殊记忆等多个方面，Genie 3都实现了突破。

它甚至可以让个人创造自己的游戏世界、训练强化学习的智能体、机器人研究等。

所有这些应用基本上都源于一个核心能力：**只用几句话就能生成一个完整的世界。**

**最关键的新特性是：特殊记忆。**

比如：一个角色拿着刷子在墙上刷漆，然后他移动到墙的另一边去刷，接着又回到原来的位置，结果之前刷的痕迹还在。

特殊记忆（special memory）是DeepMind团队有意设计的目标，但最终的效果好得出乎意料。

即便是参与Genie 3的内部成员，第一次看到上面刷墙的示例时也不敢相信，需要再三观看、逐帧检查，才确定这真的是模型生成的。

![](https://img.36krcdn.com/hsossms/20250817/v2_beaa3a8e469c44d19acb827db0d83de4@5579416_oswg267348oswg1080oswg231_img_000?x-oss-process=image/format,jpg/interlace,1)

Genie 3的一致性非常高：建筑物左侧的树木在整个交互过程中始终保持一致，即使它们时而进入视野时而消失

其实，Genie 2就已经具备了一些「记忆能力」。但当时，整个AI界太多令人激动的模型发布，比如Veo 2模型几天后也发布了。而且，当时谷歌主打的卖点是「可以生成新的世界」，所以记忆能力就没被强调出来。

到了Genie 3，在「记忆」上，谷歌DeepMind下了更大的决心，明确地把「增强记忆能力」作为核心目标之一。

当时设定的目标是：

**超过一分钟的记忆、**

**支持「实时生成」、**

**还能提升「分辨率」。**

其实，这几个目标本身是互相矛盾的，但谷歌无所畏惧。

说实话，直到项目快结束时，在看到最终样本的那一刻，他们依然感到震撼。这种成果即使是预期中的，真的实现的时候还是非常令人兴奋。毕竟，研究项目永远不会有百分百的确定性。

在设计上，他们还有一个明确的方向，就是**不采用「显式表示法」**。市面上已有一些方法，比如用NeRF或Gaussian Splatting等技术，通过构建明确的3D世界结构，来达到一致性。这些方法很好，在某些应用上效果不错。

但他们坚持让模型「逐帧生成」，这种方式对模型的泛化能力、适应多样世界的能力更有帮助。

### **智能涌现，惊喜不断**

就像其他生成式模型一样，随着Scaling，效果确实会提升，这已经不是什么秘密了。

尽管不如语言模型在推理能力上的涌现表现，Genie 3依然**涌现出一些令人惊讶的行为**。比如说，如果一个角色靠近一扇门，模型可能就会「推测」角色应该打开门；这类符合人类直觉的行为，模型现在能在一定程度上表现出来了。

还有就是对语言的理解在不断变好，生成的内容也越来越真实，视觉效果更自然。

从Genie 2到Genie 3的提升非常明显，特别是在「模拟现实世界能力」上有巨大飞跃。

比如物理效果的表现——像水的模拟、光照的变化，都非常惊艳。

现在已经到了一个地步，哪怕是非专业人士，看了之后也会觉得是真实拍摄的视频。

这太惊人了。而在Genie 2时代，模型虽然大致能表现出物体该有的行为，但你还是一眼能看出「这是AI生成的，不是真的」。

**现在的视频真假难辨，进步真的很大了。**

在「地形多样性」问题：比如模型需要理解在沙地上行走、在下坡滑雪、在水中游泳，这些动作和物理反馈应该是不一样的。

谷歌团队发现这些行为很多都是规模和数据广度所带来的「涌现能力」。

换句话说，他们并没有为这些行为做专门的训练或设计，而是模型自己「学」出来的。它通过足够丰富的训练数据，掌握了这个「世界」的通用常识。大多数时候，它表现非常不错。

比如下面的例子：

在滑雪时，角色在下坡时速度会变快，而试图上坡时就会变慢，甚至爬不上去；

下水后，角色一般会开始游泳或溅起水花；

靠近水坑时，模型通常也会让角色穿上雨靴。

这些行为都非常自然，和人类对真实世界的理解非常一致，而这些都是模型自己学会的，真的让人觉得像魔法一样。

这里还有一个有趣的**权衡：既能保持世界的「物理一致性」，同时也能忠实地执行用户的提示词。**

对视频模型来说，「低概率事件」本来很难，但Genie 3依然能有不错的表现。

这正是它的魅力所在：

即便是一些现实中不太可能发生的场景，Genie 3也能让你如临其境，而不是仅仅生成一个和你身边环境一样的无聊视频。

在「指令跟随/文本对齐」，Genie 3也得到了提升，这主要得益于DeepMind内部不同项目（特别是Veo项目）的经验迁移和知识共享。这种**跨团队协作是DeepMind的优势**。

世界模型是让智能体走向现实世界最快的路径。Genie 3朝着这个目标迈出了一大步。

那Genie 4、Genie 5的新特性有哪些设想？

### **未来的关键，真实感和交互性**

但总的来说，Genie 3团队最关注的始终是一件事：让模型本身变得尽可能强大，让它能产生更广泛的影响，然后把创造应用的机会交给其他团队。

他们表示最终会开放Genie 3模型。

未来确实让人特别兴奋，但也必须承认，世界模型距离真正「准确模拟现实世界」还有很大差距。

比如，把一个人放进生成的世界里，让他随心所欲地做任何事情，我们还远远做不到。

还有很多工作要做，才能让虚拟世界的真实感和自由度接近现实。

应用还有很多，关键在于能否**准确模拟世界，并把人放进其中**。也许还能从「第三视角」观察自己，或者与虚拟智能体互动。

**他们还透露真实感**和**交互性**是未来的关键。

现在机器人领域最大的瓶颈之一就是数据：能收集到的数据非常有限。

而Genie 3能生成几乎无限的场景，这样一来机器人就能在虚拟世界里学习，而不再局限于现实中能采集到的视频。这个想法真的很令人兴奋。

最后一个问题：人类是不是生活在某种模拟中？

这个问题被问过很多次，得到了「哲学化」的回答：如果真是模拟，那它运行在完全不同的硬件之上

如果人类真的生活在一个模拟世界里，那它绝对不是运行在现在的硬件上的。因为我们的世界是**连续的**，而不是数字化的。

所有的感知都是连续的信号。

也许，在量子层面会有一些「硬件限制」，但至少和我们现在的计算机完全不同。

或许未来量子计算机，才是运行我们这个模拟世界的真正平台。

本文来自微信公众号[“新智元”](https://mp.weixin.qq.com/s/mqTTlbWjtYZd3tGcgqhUzw)，作者：新智元，36氪经授权发布。
