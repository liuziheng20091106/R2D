> id: https://www.36kr.com/p/3435332170124929

> link: https://www.36kr.com/p/3435332170124929

> title: 177

# 177
_Published on Sun, 24 Aug 2025 00:32:54 GMT_

DeepSeek涨价了。 

智东西8月23日报道，8月21日，DeepSeek在其公众号官宣了DeepSeek-V3.1的正式发布，还宣布自9月6日起，DeepSeek将执行新价格表，**取消了今年2月底推出的夜间优惠**，推理与非推理API统一定价，输出价格调整至12元/百万tokens。这一决定，**让使用DeepSeek API的最低价格较过去上升了50%。**

DeepSeek在业内曾有“价格屠夫”的称号，在2024年5月凭借DeepSeek-V2，将API价格降至**输入1元/百万tokens、输出2元/百万tokens**的行业低价，一石激起千层浪。 

仅在当月，就有**智谱、字节、阿里、百度、讯飞、腾讯**等厂商跟进降价，**最高降幅达到80%-97%**，还有部分厂商直接将轻量级模型**免费开放**，掀起一场持续半年多的大模型价格战。 

![](https://img.36krcdn.com/hsossms/20250823/v2_dc73ec5bfda64677af428204ea977d13@000000_oswg107445oswg1000oswg838_img_000?x-oss-process=image/format,jpg/interlace,1)

▲2024年5月部分厂商发布的大模型降价通知

然而，在2025年，却有越来越多的厂商选择了停止降价。在国内，“大模型六小虎”中，已有智谱、月之暗面、MiniMax、阶跃星辰**4家对部分API价格进行上调**，百川智能、零一万物**2家保持价格不变**；阿里、字节、腾讯、百度、科大讯飞、商汤等大厂们广泛采用**阶梯定价策略**，或是**拉开“推理”与“非推理”模式差距。**行业的整体API价格趋于稳定，部分产品还出现了明显上浮。 

国际厂商虽然仍在宣称智能将越来越便宜，但实际情况却是，过去一年OpenAI、Anthropic、谷歌等企业的API价格**基本原地踏步，甚至有小幅上涨**。与此同时，订阅方案越来越贵，顶级模型几乎被锁在200美元/月及以上的高价档里，xAI甚至推出了300美元/月的订阅方案。 

在这样的背景下，DeepSeek涨价只是更大规模行业趋势的一个缩影：**当前，大模型价格的下行速度正逐渐放缓，顶级AI服务不再无限下探，反而开始呈现趋于稳定，略有回升的态势。**

**以下数据均收集于公开渠道，如有错漏欢迎指正。**

**01.DeepSeek、大模型六小虎API价格普涨，但有两家近1年没改价**
----------------------------------------

大模型价格战，曾经是2024年国内AI圈最火的关键词之一，大模型API的价格曾经一度降至每百万tokens几毛钱。然而，进入2025年后，这一降价趋势却基本停滞，**尤其是对于那些最先进的模型而言。**

以DeepSeek为例，去年年底DeepSeek-V3刚刚发布时，DeepSeek进行了45天的限时优惠，结束后，DeepSeek-Chat API（非推理API）中输出价格从2元恢复到8元；这一API的价格将于今年9月份进一步上浮50%，至12元。 

![](https://img.36krcdn.com/hsossms/20250823/v2_d95384d04ef74b898d54e1da3024afcc@000000_oswg59931oswg1080oswg484_img_000?x-oss-process=image/format,jpg/interlace,1)

Deepseek-Reason API（推理API）的价格则相对稳定，并且会在今年9月份将输出价格从16元降至12元。不过，总体来看，**DeepSeek API的价格还是呈上涨趋势。**

![](https://img.36krcdn.com/hsossms/20250823/v2_8c511bc50b3e4248afa314ab4e4dfaa3@000000_oswg67698oswg500oswg499_img_000?x-oss-process=image/format,jpg/interlace,1)

▲DeepSeek API价格变动情况（智东西制图）

大模型六小虎中，智谱、月之暗面、百川智能、MiniMax、阶跃星辰、零一万物的价格，在2025年1季度之后，基本没有出现明显的下降。 

智谱上一代GLM-4模型的API定价不区分输入输出与输入token数量，统一为5元/百万tokens。而其今年7月发布的GLM-4.5模型，在去除模型发布之初的限时优惠政策后，高速推理版本（GLM-4.5-X）的输出价格**最高可达到64元/百万tokens**。 

即使是按照最低档计价（使用GLM-4.5，输出长度小于32K，输出长度小于0.2K，推理速度为30-50tokens/秒），其输出价格也从5元/百万tokens变成了8元/百万tokens。 

![](https://img.36krcdn.com/hsossms/20250823/v2_95e18880bacc4a97a259065a2ae78325@000000_oswg110909oswg1000oswg590_img_000?x-oss-process=image/format,jpg/interlace,1)

▲GLM-4.5定价情况（图源：智谱开放平台官网）

月之暗面2024年8月正式推出企业API，彼时在128K上下文场景中，其输入输出定价均为60元/百万tokens，在业内属于较高水平。 

今年4月，月之暗面对部分API价格进行了调整，使用其最新K1.5模型的API输出价格降至30元/百万tokens，但在Kimi K2推出后，128K上下文场景中的高速输出价格又回调至**64元/百万tokens**。 

![](https://img.36krcdn.com/hsossms/20250823/v2_4cf84ecef5c24592ab790da2b4c2071d@000000_oswg51466oswg500oswg400_img_000?x-oss-process=image/format,jpg/interlace,1)

▲月之暗面Kimi大模型API定价变化，选取的数据均为最高档次定价（智东西制图）

百川智能已经长期没有对API价格进行调整，旗舰模型Baichuan4的调用价格自2024年5月发布以来，一直维持在输入输出均为100元/百万tokens的水平。 

![](https://img.36krcdn.com/hsossms/20250823/v2_a8d68919949e47fab83e7118f509ee06@000000_oswg75308oswg1000oswg253_img_000?x-oss-process=image/format,jpg/interlace,1)

▲百川智能API价格表（图源：百川智能）

2024年8月，MiniMax对其当时的旗舰文本生成模型abab-6.5s进行了大幅度的降价，输入和输出价格均统一为**1元/百万tokens**。不过，目前这一模型在其API开放平台上已不可见。 

MiniMax新一代文本生成模型MiniMax-Text-01（2025年1月发布）的定价为输入1元/百万tokens，**输出8元/百万tokens**；而其推理模型MiniMax-M1（2025年6月发布）的价格则采用阶梯定价，最高价格为输入2.4元/百万token，**输出24元/百万token**。 

![](https://img.36krcdn.com/hsossms/20250823/v2_bee6fe2696664fbdbd2d74051ff0707f@000000_oswg36959oswg500oswg394_img_000?x-oss-process=image/format,jpg/interlace,1)

▲MiniMax大模型API定价变化趋势，选取的数据均为最高档次定价（智东西制图）

阶跃星辰以多模态为特色。今年4月，该公司发布了Step-R1-V-Mini多模态推理模型，**输出价格为8元/百万tokens**。其7月发布的新一代多模态推理模型Step 3调整为阶梯定价，输入≤4k的价格基本持平或**略有下调**，在最高档（4k < 输入≤ 64k）的价格有一定上涨，**输出价格为10元/百万tokens**。同时，Step 3最大上下文窗口为64K，较Step-R1-V-Mini的100K有所缩小。 

![](https://img.36krcdn.com/hsossms/20250823/v2_87fd6558724b419ea54b8dc4e3ffe653@000000_oswg38609oswg500oswg404_img_000?x-oss-process=image/format,jpg/interlace,1)

▲阶跃星辰大模型API定价变化趋势，选取的数据均为最高档次定价（智东西制图）

零一万物于2024年10月发布Yi-Lighting，价格为0.99元/百万tokens，**此后未再更新API中的模型价格**。如今调用Yi-Lighting时，还会根据用户输入智能路由到DeepSeek-V3、Qwen-30B-A3B等模型。 

![](https://img.36krcdn.com/hsossms/20250823/v2_22157b94d97245f5aee060f786b1032c@000000_oswg159650oswg1000oswg330_img_000?x-oss-process=image/format,jpg/interlace,1)

▲零一万物大模型API定价表（图源：零一万物）

**02.多家大厂细化定价规则，有模型输出超300字就得加钱**
--------------------------------

更为“财大气粗”的大厂们，也在2025年放缓了模型降价的脚步。 

字节跳动在2024年5月首次推出豆包Pro家族，小于32K上下文的豆包通用模型Pro输入价格仅为0.8元/百万tokens，输出价格为2元/百万tokens。字节跳动火山引擎总裁谭待在发布会上称，**这一定价“比行业价格低99.3%”**。这次发布也将大模型价格战推至舆论的风口浪尖。 

在32K上下文的场景下，2025年1月发布的豆包1.5 Pro与2025年7月的豆包1.6，维持了豆包通用模型Pro的价格水平。 

不过，字节进一步细化了定价规则，根据输入、输出两个变量调整定价。**当模型输出超过200个token（约为300个汉字）时，豆包1.6的输出价变为8元/百万tokens**，输入价不变。 

![](https://img.36krcdn.com/hsossms/20250823/v2_a4f93a6d8ea5468ab9ff7809beb1ba57@000000_oswg64995oswg1000oswg371_img_000?x-oss-process=image/format,jpg/interlace,1)

▲豆包1.6阶梯定价细则（图源：火山方舟）

从初代豆包Pro，到豆包1.5 Pro，再到豆包1.6，字节豆包大模型API的最高价变化趋势如下： 

![](https://img.36krcdn.com/hsossms/20250823/v2_20109c4c9388425e89ea1d703f1f31cb@000000_oswg43136oswg500oswg383_img_000?x-oss-process=image/format,jpg/interlace,1)

▲字节跳动豆包大模型API定价变化趋势，选取的数据均为最高档次定价（智东西制图）

阿里巴巴通过阿里云百炼对外提供大模型API服务，由于阿里旗下的大模型数量众多，更新频率较快，且有开源版与商业版之分，全部统计将略显庞杂。智东西主要追踪了2025年以来其主力商业API服务之一Qwen-Plus的价格变化。 

可以看到，Qwen-Plus在今年4月份新版本推出，并引入思考与非思考模式的区别后，思考型输出的价格来到了非思考输出的4倍。 

今年7月版本更新后，Qwen-Plus全面采用阶梯定价的形式，128K输入以下的调用价格与4月份定价持平，但当输入量超过128K时，价格出现明显上涨，**最高输出价格达到了64元/百万tokens。**

![](https://img.36krcdn.com/hsossms/20250823/v2_718f49c8faa04bd3854542f0739cfe6c@000000_oswg151474oswg1000oswg500_img_000?x-oss-process=image/format,jpg/interlace,1)

▲阿里Qwen-Plus API价格变动情况（智东西制表）

2024年7月，百度宣布将其旗舰模型ERNIE 4.0降价，以输入40元/百万tokens、输出120元/百万tokens的价格对外提供服务，百度后续逐渐将ERNIE 4.0的推理价格降至业内常见的输入4元/百万tokens、输出16元/百万tokens（未查询到这一降价的具体时间），今年3月推出的ERNIE 4.5维持了这一定价，**没有继续下降。**

![](https://img.36krcdn.com/hsossms/20250823/v2_cc6bd16f8e5c4fe4a88a964b9dc3529b@000000_oswg22800oswg1000oswg299_img_000?x-oss-process=image/format,jpg/interlace,1)

▲ERNIE 4.0、ERNIE 4.5模型价格（图源：百度）

腾讯是国内几家大厂中少数仍在逐渐下调大模型API价格的企业。2024年9月，腾讯发布了混元Turbo大模型，定价为输入15元/百万tokens、输出50元/百万tokens，在当时属于较高水平。 

不过，目前混元Turbo的价格已经降至输入2.4元/百万tokens、输出9.6元/百万tokens，2025年3月发布的混元TurboS价格则**降至输入0.8元/百万tokens、输出2元/百万tokens。**

![](https://img.36krcdn.com/hsossms/20250823/v2_057a52c4cfa04ed19570bad103acee2c@000000_oswg37625oswg1000oswg248_img_000?x-oss-process=image/format,jpg/interlace,1)

▲部分腾讯混元大模型的价格（图源：腾讯云）

科大讯飞的API服务按照token包计费，不区分输入输出，不同套餐折合后的token单价不同。 

按照价格区间的中值计算，2024年1月推出的星火3.5的价格约为25元/百万tokens，同年6月推出的星火4.0价格约为60元/百万tokens，同年10月发布的星火4.0 Turbo，以及2025年1月升级后的新版星火4.0 Turbo，都维持了这一价格。 

![](https://img.36krcdn.com/hsossms/20250823/v2_7ddb1871d8b34d97bcc493b3bd182a2d@000000_oswg34018oswg500oswg396_img_000?x-oss-process=image/format,jpg/interlace,1)

▲讯飞星火3.5、星火4.0、星火4.0 Turbo价格变化（智东西制图）

不过，讯飞也推出了一款基于全国产算力训练的深度推理大模型星火X1，其价格约为11元/百万tokens。 

商汤旗舰模型日日新系列的API价格从2024年5月的20元/百万tokens，回落至2025年4月的9元/百万tokens，今年7月最新发布的SenseNova-V6.5 Pro维持了这一价格。 

![](https://img.36krcdn.com/hsossms/20250823/v2_3eb9bb503e7f4023aff05f0aba65f1a5@000000_oswg48468oswg500oswg387_img_000?x-oss-process=image/format,jpg/interlace,1)

▲对应模型分别为日日新SenseChat-5-1202、SenseNova-V6-Pro、SenseNova-V6.5 Pro，均为当时商汤已发布的最先进模型（智东西制图）

**03.海外大模型厂商“说一套做一套”，订阅方案涨至200美元级别**
------------------------------------

国际主流大模型厂商之间，虽没有出现明显的价格战现象，但“鼓吹”智能的成本将不断降低，是海外AI圈几位大咖们最热衷的话题之一。 

今年7月，OpenAI联合创始人、首席执行官Sam Altman说道：“智能的价格将低到无法计量，我们能将每个单位的智能的成本，每年降低至原来的1/10，至少持续5年。” 

2024年9月，谷歌首席执行官Sundar Pichai分享了同样的观点：“在不久的将来，智能将像空气一样丰富，并且基本上对所有人免费。” 

近期，The Information的统计数据揭示了一个与上述观点相悖的现实，**海外主要大模型厂商的API价格在2024年7月后的1年多时间里，就没有出现明显的下降，甚至还有轻微的涨幅。**

例如，OpenAI的GPT系列模型每百万tokens的价格，自从2024年底降至12.5美元之后，便没有继续大幅度下探，目前维持在11.25美元的水平。 

Anthropic的Claude 3、Claude 4系列模型，自推出以来就从未降价。 

谷歌的Gemini Pro模型的调用价格出现上涨，从Gemini-1.5 Pro的12.5美元/百万tokens涨至17.5美元/百万tokens。 

![](https://img.36krcdn.com/hsossms/20250823/v2_31c2669479b44e12a58e42876812753b@000000_img_000?x-oss-process=image/format,jpg/interlace,1)

▲最先进的通用模型价格近期基本没有出现下降（图源：The Information）

过去一年中，多家海外头部AI公司还相继推出了月费超过200美元的高阶订阅方案。 

OpenAI与Anthropic均推出了**200美元/月的订阅档位**；谷歌最新的AI Ultra捆绑包定价为**249.99美元/月**；xAI旗下的Grok更进一步，将其顶级订阅方案设定为**300美元/月**的高价。 

这些高端订阅服务的共同特点是：用户只有支付超高额的月费，才能使用到各家在发布会上展示的跑分最高、性能最强的旗舰模型。无论是更强的推理能力、更长的上下文窗口，还是更精准的代码或复杂任务处理能力，均被保留在付费墙之后，**高性能模型成为高付费用户专属的资源。**

那么，究竟是什么原因，导致了过去一段时间内AI服务价格下降趋势的明显停滞，甚至出现逆向走高呢？ 

**04.算力、数据、人才价格持续推高，大模型玩家们也要考虑ROI**
-----------------------------------

大模型厂商们在算力、数据以及人才等方面的巨大投入，驱动了过去1年AI模型性能的飞速提升。 

算力方面，GPU的租赁价格目前已经趋于稳定。智东西收集的数据显示，2024年9月左右，AWS、微软Azure、谷歌云等主流公有云上的H100每卡时租赁价格大约**在5-11美元的区间。**

今年，根据算力市场数据分析公司Silicon Data的GPU价格指数，H100已经基本**稳定在每卡时租赁价格2-3美元的区间**，没有出现价格的大幅度波动。 

![](https://img.36krcdn.com/hsossms/20250823/v2_16a93067ed754e6cac29cb19689f6e41@000000_oswg95937oswg1000oswg608_img_000?x-oss-process=image/format,jpg/interlace,1)

▲H100 GPU租赁价格（图源：Silicon Data）

同时，新一代大模型无论是在训练还是推理阶段，算力需求都在不断增加。在与相对稳定的GPU价格复合后，**算力成本成为限制AI服务价格继续下探的“硬门槛”之一。**

数据也是当今大模型训练中不可忽视的成本项。起初，由于监管缺位，大模型训练数据的获取成本相对较低。随着相关诉讼增多和合规审查趋严，为了避免与数据所有者发生法律纠纷，厂商开始主动与企业签订合同，购买授权数据。 

例如，据《华尔街日报》报道，OpenAI与美国出版集团News Corp签署的5年数据使用协议金额可能高达**2.5亿美元**；谷歌则与美国的贴吧类平台Reddit达成AI使用内容许可协议，路透社报道称，其**每年价格约为6000万美元。**

与此同时，这些模型背后**人才的价格**，也在水涨船高。 

在国内，猎聘大数据研究院7月份发布的《2025上半年人才供需洞察报告》显示当前国内AI人才缺口已突破500万，AI技术人员**平均年薪为32.35万元**，50万年薪以上的AI技术岗占比高达31.03%。AI技术人才的期望年资甚至高于如今的平均年资，为44.09万元。 

大洋彼岸，硅谷的AI人才争夺战打得火热。除了那些数亿美元的个别案例之外，AI人才的整体薪资水平也明显高于其他行业。国际职场平台Levels.FYI上的数据显示，在旧金山湾区，ML/AI工程师的薪资中位数要比所有软件工程师的薪资中位数**高13%左右**。考虑到所有软件工程师的统计范畴内包含了ML/AI工程师，**后者的薪资优势可能更大。**

![](https://img.36krcdn.com/hsossms/20250823/v2_c893994b5c9f4e9399c35a2ef37ab9de@000000_oswg63585oswg1000oswg910_img_000?x-oss-process=image/format,jpg/interlace,1)

▲美国旧金山湾区ML/AI工程师薪资（图源：Levels.FYI）

**05.订阅模式面临服务成本考验，成本控制迫在眉睫**
----------------------------

打造大模型的成本越来越高昂，而随着推理模型范式的兴起，以及Agent等长序列任务的出现，用户的用量正在不断攀升。大模型订阅就像是一张**“无限流量卡”**，用户用得越多，大模型厂商们提供服务的成本便越高，有部分厂商已经被用户逼到了入不敷出的程度。 

本月，Anthropic旗下的Claude Code编程Agent便取消了200美元/月订阅方案的无限调用大模型权限，原因是有用户几乎24小时不停地使用大模型，为这些用户提供AI服务的成本已经达到了**每月数万美元**，远超订阅方案的定价。 

Anthropic更是在发布会上宣称，Claude 4 Opus能连续7小时工作，完成编程类任务。按照Claude 4 Opus大约50 tokens/秒的推理速度计算，这一任务大约会用掉126万个token，成本约113.4美元。 

面临高昂的服务成本，大模型厂商们纷纷祭出各种手段来降低开支。 

DeepSeek在其最新一代模型中提出了多种降本方法。例如，在对DeepSeek-V3.1进行思维链压缩训练后，模型推理时输出token数可减少20%-50%，且各项任务的平均表现与DeepSeek-R1-0528持平。这意味着DeepSeek的聊天机器人，能在不影响 

DeepSeek-V3.1还在一个模型内支持了思考模式与非思考模式，开发者可通过特定标签控制推理的开关，进一步节省API使用成本。 

腾讯混元降本的思路是架构创新。在混元TurboS上，腾讯融合了两种架构，让Transformer的上下文理解力与Mamba的长序列处理能力结合，实现性能与效率的平衡。 

OpenAI在GPT-5上采取了“模型自动路由”的方式：判断任务的复杂度，将相对简单的需求分配给轻量模型处理，从而节省算力资源。托管GPT-5的微软Azure称，这一方式最高可将推理成本削减60%。 

然而，问题的关键在于：**大模型厂商和云服务提供商的成本下降，并不必然传导为终端用户与企业的使用成本下降。**当前，如何在高昂的前期研发与部署投入后，将千亿美元级别的AI投资真正转化为商业价值，已成为所有大模型玩家必须回答的问题。 

**06.结论：大模型价格还有下探空间吗？**
-----------------------

未来，大模型价格的下降还存在几条路径。一方面，随着模型平均性能的提升，未来经过优化的中低端廉价模型，也可高效解决特定任务。此外，随着大模型、芯片领域的基础研究不断进步，新的技术路径持续涌现，或许能在不牺牲效果的前提下，进一步压缩训练与推理的单位成本。 

从产业发展的角度来看，大模型价格的阶段性停滞或是回升有其价值。这为厂商回收前期巨额研发与基础设施投入，维持可持续创新提供了缓冲期，也能推动市场加速探索明确的商业化场景和付费模式。产业有望借此机会，营造更为成熟、健康的生态。 

本文来自微信公众号 [“智东西”（ID：zhidxcom）](https://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&mid=2652788027&idx=1&sn=d4d731004cbae76b64249d017af59ed4&chksm=85a19c2d0f9207be52ec0ebe2a853a478c495daee2e3103cc05adeba65f4e158ba5feb6ae3f1&scene=0&xtrack=1#rd)，作者：陈骏达，编辑：心缘 ，36氪经授权发布。
