> id: https://www.36kr.com/p/3435572235767177

> link: https://www.36kr.com/p/3435572235767177

> title: DeepSeek

# DeepSeek
_Published on Sun, 24 Aug 2025 23:30:32 GMT_

DeepSeek V3.1 一上线，官方的一条留言就把整个 AI 圈炸了。

新的架构、下一代国产芯片，短短不到 20 个字，却信息量满满，引发热议。

![](https://img.36krcdn.com/hsossms/20250823/v2_6386fbff6f224da79d6a1b419144f592@000000_oswg25030oswg604oswg198_img_000?x-oss-process=image/format,jpg/interlace,1)

这两天老狐看了不少科普文后，简单理解就是：国产 AI 正在走向软硬协同阶段，未来模型有望实质性减少对英伟达、AMD 等国外算力的依赖。

同时，这次更新还打破了“性能越高成本越贵”的行业魔咒，让金融、医疗等高算力场景的应用想象空间一下子被打开。

资本市场的反应也很直接：DeepSeek 一官宣，国产芯片概念股应声大涨，每日互动尾盘直线拉升，收盘大涨 13.62%。

![](https://img.36krcdn.com/hsossms/20250823/v2_ab0bc823de174dbe99a50a834ad16f0c@000000_oswg88398oswg759oswg697_img_000?x-oss-process=image/format,jpg/interlace,1)

有网友调侃说：国产芯片迎来史诗级暴涨，DeepSeek 一句话，周五大盘直接冲上 3800 点。

这两天，DeepSeek 官方上线 V3.1 版本，没铺天盖地宣传，就像平常一样低调发个公告。

![](https://img.36krcdn.com/hsossms/20250823/v2_4eb547413fd64cc0b3a5b3e5a43abb1f@000000_oswg352807oswg1080oswg946_img_000?x-oss-process=image/format,jpg/interlace,1)

老狐整理了一下这次 V3.1 的更新，最核心、最有革命性的创新，就是它的混合推理架构——Hybrid Reasoning Architecture。

这个架构能同时支持思考模式和非思考模式，用户可以随时切换，想慢慢分析就慢慢分析，想快速出结果也没问题。

![](https://img.36krcdn.com/hsossms/20250823/v2_0b290cbe612a45098b20333f41ed23cf@000000_oswg55068oswg1080oswg539_img_000?x-oss-process=image/format,jpg/interlace,1)

以前 DeepSeek 的产品线里，分工很清楚：V3 模型擅长通用对话，R1 模型更偏深度思考。这种分离式架构好处是，各个模型都能在自己擅长的领域表现不错，但用户来回切换很麻烦。

现在，V3.1 打破了这种壁垒，把通用对话、复杂推理、专业编程等多种核心功能集成在同一个模型里，让使用体验更灵活，效率更高。

不仅如此，V3.1 的推理效率也大幅提升。官方数据显示，思考模式下，它在各项任务的平均表现和前代顶级 R1-0528 持平，但输出的 token 数量减少了 20% 到 50%。非思考模式下，输出长度也更短，但性能不打折。

![](https://img.36krcdn.com/hsossms/20250823/v2_8fec899fb9a5442aa46482d43900a0d6@000000_oswg169043oswg1080oswg468_img_000?x-oss-process=image/format,jpg/interlace,1)

这背后其实是“思维链压缩”在起作用：模型在训练阶段学会生成更简洁、高效的推理路径，同时保证答案准确。简单理解，就是算法更聪明了。

为什么要这样做？很简单：省钱！

过去，思维链虽然能让模型推理更强，但冗长的中间步骤会带来高昂计算成本和 API 调用费用，想大规模应用就很难

V3.1 的思维链压缩，正好解决了这个问题，把高级 AI 推理能力从学术工具变成了可大规模商业化使用的经济方案。

社区测试中，DeepSeek V3.1 在 Aider 多语言编程测试里，分数已经超过了 Claude 4 Opus，而且成本还更低。

![](https://img.36krcdn.com/hsossms/20250823/v2_8ff7e9ca230b4e269cab60620562ab44@000000_oswg420993oswg1036oswg978_img_000?x-oss-process=image/format,jpg/interlace,1)

这下开发者都在刷屏了，Hugging Face 上的热度也蹭蹭往上。

![](https://img.36krcdn.com/hsossms/20250823/v2_6de8cac8748e4394b621d12af8c69f0c@000000_oswg66017oswg1080oswg517_img_000?x-oss-process=image/format,jpg/interlace,1)

值得一提的是，DeepSeek 官宣 V3.1 的时候提到，这次模型用了 UE8M0 FP8 Scale 的参数精度，同时对分词器和 chat template 也做了不小的调整，所以和之前的 V3 有明显区别。

说到 DeepSeek V3.1 用的 “UE8M0 FP8”， 老狐简单学习后科普一下：

FP8 就是把普通浮点数压缩成 8 位来存，既省空间又省算力。

![](https://img.36krcdn.com/hsossms/20250823/v2_3334da775ed04f7ba47ed94ae765db61@000000_oswg67847oswg1080oswg510_img_000?x-oss-process=image/format,jpg/interlace,1)

再加上 MXFP8 的“块缩放”思路：把数据分块，每块用自己的缩放系数，这样既不会丢太多信息，又能节省更多资源。

名字里的 U、E、M 可以理解为“无符号 + 指数 + 尾数”。UE8M0 里所有 8 位都用来表示指数，没有尾数和符号位，这让处理器复原数据时非常轻松：只要移动指数位就行，不用做复杂乘法，速度快、路径短。

这个格式的另一个优势是动态范围大，可以同时表示很大和很小的数，不容易溢出或被压成 0，也就是在保证 8 位张量精度的同时，把信息损失降到最低。

![](https://img.36krcdn.com/hsossms/20250823/v2_2c79dad219ab4b01889f49ae1a8a9025@000000_oswg25367oswg585oswg237_img_000?x-oss-process=image/format,jpg/interlace,1)

这对国产新芯片特别合适，以前大部分国产 AI 芯片用的还是 FP16/INT8，没法原生用 FP8。

为什么说它更适合下一代国产芯片？目前大部分国产 AI 加速器还是 FP16/INT8 方案，没有完整的 FP8 单元。

新一代芯片，比如摩尔线程 MUSA 3.1 GPU、芯原 VIP9000 NPU，都开始支持原生 FP8，DeepSeek V3.1 的 UE8M0 格式正好匹配这些硬件。

总结一句话：UE8M0 FP8 让模型在新一代国产芯片上跑得更省空间、更快、更稳，同时保持精度。

这也是为什么 DeepSeek 官微特别提到它，为国产 AI 带来了更低成本、高性能的新可能。

再来看看更新后一些体验，大家关心的官网能不能直接访问，官方也给出了答案。

![](https://img.36krcdn.com/hsossms/20250823/v2_028bef99d6e24cce9f71885b6d389f19@000000_oswg58553oswg1080oswg220_img_000?x-oss-process=image/format,jpg/interlace,1)

打开官网一看，DeepSeek 把 App 和网页端的“深度思考（R1）”改成了“深度思考”，官方确认了网友之前的猜测——模型已经更新了。

看看万能的网友们，都玩出了什么新花样。

推特 X 上有 AI 博主分析新模型生成的小球跳动效果更符合物理定律了，还能调重力、摩擦、旋转速度、弹跳这些参数。

![](https://img.36krcdn.com/hsossms/20250823/v2_3eb0c91532644dd39ca129949957fe74@000000_oswg326740oswg1016oswg996_img_000?x-oss-process=image/format,jpg/interlace,1)

还有人直接用 DeepSeek V3.1 做了个振动编码，当场变身 VJ。

![](https://img.36krcdn.com/hsossms/20250823/v2_65e697b71476453dbe7554701a2361a8@000000_oswg450291oswg1066oswg900_img_000?x-oss-process=image/format,jpg/interlace,1)

更有网友让 V3.1 给自己画了个自画像，画风意外特别。

![](https://img.36krcdn.com/hsossms/20250823/v2_5d991b6107d1452caf8f63a4dfe9cfbe@000000_oswg56859oswg1000oswg983_img_000?x-oss-process=image/format,jpg/interlace,1)

不过，社区中还是有部分用户吐槽翻译和写作，SYSTEM PROMPT 需要现场写指令，中英夹杂和错词偶尔出现，有点乱。

![](https://img.36krcdn.com/hsossms/20250823/v2_b5dce5bb695447009ce14204eaae4f7f@000000_oswg82282oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1)

感兴趣的狐友们，现在可以上官网自行体验一番了~

老狐觉得每次 DeepSeek 更新都让人期待下一次，几乎快成了国产 AI 的精神图腾了，一起期待 DeepSeek R2 吧。

本文来自微信公众号[“科技狐”（ID：kejihutv）](https://mp.weixin.qq.com/s?__biz=MzU2MzcyNzgzOQ==&mid=2247859946&idx=2&sn=7394eb0a77448b228416ac3bf73a1258&chksm=fd1378f2273b392001e535a389563f1f9aac64092429278760aa401e4773e62cbad358718206&scene=0&xtrack=1#rd)，作者：老狐，36氪经授权发布。
