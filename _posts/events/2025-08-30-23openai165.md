> id: https://www.36kr.com/p/3444824032613768

> link: https://www.36kr.com/p/3444824032613768

> title: 23OpenAI165

# 23OpenAI165
_Published on Sat, 30 Aug 2025 07:00:33 GMT_

23 岁被 OpenAI 开除，利用自己的「内部消息」打造了一支规模达 15 亿美元的基金，今年这支基金的表现还比华尔街高出 700%。

如此跌宕起伏的人生，你就说刺不刺激？

![](https://img.36krcdn.com/hsossms/20250830/v2_99178a779a964222b60e1ff4653a8dcd@000000_oswg420241oswg880oswg1011_img_000?x-oss-process=image/format,jpg/interlace,1)

最近，这个名叫 Leopold Aschenbrenner 的小哥因这段离谱的经历在社交媒体上火了。《华尔街日报》等媒体报道了他迅速蹿升的故事。

![](https://img.36krcdn.com/hsossms/20250830/v2_4d9dab03b4d74796b9ffaa85c4614d8a@000000_oswg89435oswg1080oswg929_img_000?x-oss-process=image/format,jpg/interlace,1)

Aschenbrenner 本是 OpenAI 知名的「超级对齐」团队成员，被认为是 OpenAI 前首席科学家 Ilya Sutskever 的嫡系，不过后来因涉嫌泄露公司内部信息而被 OpenAI 解雇。

![](https://img.36krcdn.com/hsossms/20250830/v2_7ee503a3ccc94ee0a2bf345be808b6c7@000000_oswg213702oswg400oswg400_img_000?x-oss-process=image/format,jpg/interlace,1)

两个月后，他发布了一篇 165 页的分析文章《Situational Awareness: The Decade Ahead》，在硅谷引发广泛关注。

![](https://img.36krcdn.com/hsossms/20250830/v2_9188a68409ef487a99297823cce931b5@000000_oswg58532oswg1080oswg276_img_000?x-oss-process=image/format,jpg/interlace,1)

转头，这小哥就扎进投资领域，创建了名为 Situational Awareness 的对冲基金。

别看他没啥专业投资经验，但他的投资策略简单粗暴，就是押注那些可能从 AI 技术发展中受益的行业，如半导体、基础设施和电力公司，以及一些新兴 AI 公司，比如 Anthropic，另一边又做空那些可能被淘汰的行业来保持收益。

这一策略令该基金在短时间内吸引大量投资者，资金规模迅速突破 15 亿美元。

其背后不乏大佬支持，包括支付公司 Stripe 的创始人 Patrick 和 John Collison 两兄弟，Meta 的 AI 团队领导 Daniel Gross 和 Nat Friedman，以及著名投资者 Graham Duncan。

此外，Aschenbrenner 还招聘了曾在彼得・蒂尔宏观对冲基金工作过的 Carl Shulman，作为该基金的研究总监。

许多投资者也对该基金表现出极大的信任，愿意将资金锁定数年不动。

据《华尔街日报》报道，**该基金在今年上半年实现了 47% 的回报率，远超同期标普 500 指数的 6% 和技术对冲基金指数的 7%**，堪称市场中的一匹黑马。

Aschenbrenner 去年在接受播客主持人 Dwarkesh Patel 采访时表示：「我们将比纽约那些管理资金的人拥有更多的情境意识，肯定会在投资上做得非常出色。」

**Leopold Aschenbrenner 是谁？**

Aschenbrenner 是个 00 后，在德国出生，作为「天才少年」的他 15 岁时进入哥伦比亚大学学习，并于 19 岁时以优异成绩毕业，获得了数学、统计学和经济学三个学位，成为该校的优秀毕业生。 

![](https://img.36krcdn.com/hsossms/20250830/v2_c8ccaf0174a141419f84d67b590b5649@000000_oswg42939oswg1080oswg205_img_000?x-oss-process=image/format,jpg/interlace,1)

GPA 够高，据说还是年级第一。

毕业后，他在牛津大学的全球优先事项研究所从事长期经济增长研究，并参与了有效利他主义运动。 他曾在 FTX Future Fund 工作，专注于 AI 安全和全球风险管理。

![](https://img.36krcdn.com/hsossms/20250830/v2_78f7012f0a46497f97c892831371d510@000000_oswg239197oswg1080oswg732_img_000?x-oss-process=image/format,jpg/interlace,1)

2023 年，Aschenbrenner 加入了 OpenAI，成为「超级对齐」（Superalignment）团队的一员，致力于确保未来的超级智能 AI 与人类价值观一致。他参与过的工作，包括被广泛关注的《Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision》（https://arxiv.org/abs/2312.09390）。

在全球领先的人工智能实验室工作时，他发现了 OpenAI 可能将美国 AI 机密泄露给外国对手的安全漏洞。于是在 2024 年 4 月，他将自己的担忧写成备忘录分享给董事会成员，但时值 OpenAI「宫斗」第二季，随后以泄密为理由被 OpenAI 解雇。

![](https://img.36krcdn.com/hsossms/20250830/v2_b3a20783280844b6859586e5dfd094b3@000000_oswg884801oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1)

故事发展到这样的程度，或许只需要看做是 OpenAI 去年宫斗背景下混乱的一角，但 Leopold Aschenbrenner 显然不是等闲之辈。

**《态势感知：未来十年》**

在去年被 OpenAI 赶走后，Leopold Aschenbrenner 更加没了束缚，他在一篇长达 165 页的论文《Situational Awareness: The Decade Ahead》（态势感知：未来十年）中，阐述了自己对于 AI 发展的看法，在硅谷被广泛传阅。

他的论点简单而具革命性：**「全世界正处于人类历史上最大的变革之中，而我们还在昏昏欲睡。现在，可能只有几百人，大多数都在旧金山和人工智能实验室，能真正理解当前 AI 领域发生的事情。」**

![](https://img.36krcdn.com/hsossms/20250830/v2_6dbe0058ea6c499da34e4e2cacb7dceb@000000_oswg144559oswg1080oswg654_img_000?x-oss-process=image/format,jpg/interlace,1)

文章链接：https://situational-awareness.ai/

在文章中，作者探讨了近年来 AI 能力的指数级增长，尤其是 GPT-2 到 GPT-4 出现的过程。Leopold Aschenbrenner 强调，这是一个快速进步的时代，人工智能从完成非常基础的任务发展到拥有更复杂、类似人类的理解和语言生成能力。

![](https://img.36krcdn.com/hsossms/20250830/v2_d1b17eba519e4cc8943d599cf15c65d3@000000_oswg56021oswg1015oswg345_img_000?x-oss-process=image/format,jpg/interlace,1)

「数量级」（Orders of Magnitude，即「OOM」）的概念对于讨论至关重要。Aschenbrenner 使用数量级（OOM）来评估 AI 能力、算力和数据消耗的进步，OOM 指给定指标的十倍增长。就计算能力和数据可扩展性而言，从 GPT-2 到 GPT-4 的转换代表了许多 OOM。

![](https://img.36krcdn.com/hsossms/20250830/v2_630483063c7f424bb22b4a16d237d6fa@000000_oswg92713oswg662oswg557_img_000?x-oss-process=image/format,jpg/interlace,1)

这些收益的背后有三个主要因素 —— 扩展定律（Scaling Laws）、算法创新及海量数据集的使用，它们的增长接近于指数级。根据扩展定律，当使用更大规模的数据和处理能力进行训练时，模型的性能会得到可靠的提升。

![](https://img.36krcdn.com/hsossms/20250830/v2_4ed408a79c3b43d8af38005a8244485b@000000_oswg104861oswg776oswg439_img_000?x-oss-process=image/format,jpg/interlace,1)

算法创新也至关重要。训练方法、优化策略和底层架构的进步提升了 AI 模型的功效和效率。这些发展使模型能够更好地利用持续增长的算力和可用数据。

**Leopold Aschenbrenner 强调了到 2027 年实现通用人工智能（AGI）的可能路径。**他认为，在业界持续投入算力，提升算法效率的前提下，我们或许能够让 AI 系统在众多领域上与人类智力匹敌，甚至超越人类。

![](https://img.36krcdn.com/hsossms/20250830/v2_aa8e906355f54f2b95a6492af9abc465@000000_oswg138086oswg958oswg542_img_000?x-oss-process=image/format,jpg/interlace,1)

通用人工智能的出现无疑将产生深远的影响。这类系统能够独立解决复杂问题，以目前只有人类专家才能做到的方式进行创新，执行复杂的工作，这又赋予了 AI 系统自我进化的潜力。

AGI 的发展会改变各行各业，提高生产力和效率。但它也带来了一些重要问题，例如失业、AI 道德，需要强有力的治理结构来控制完全自主系统带来的风险。

Aschenbrenner 在文中探讨了超级智能的概念，以及从如今 AI 快速过渡到远超人类认知能力的系统的可能性。该论点的核心思想是，驱动 AI 进化的原理可能会产生一个反馈回路，一旦达到人类水平，其智力就会爆发式增长。根据「智能爆炸」的概念，AGI 可能会自行开发算法和技能，它们能够比人类研究人员更快地完善自身设计。这种自我完善的循环可能会带来智力的指数级增长。

![](https://img.36krcdn.com/hsossms/20250830/v2_dab4cc6c5e90460db16c911d63bcc836@000000_oswg234438oswg888oswg681_img_000?x-oss-process=image/format,jpg/interlace,1)

他对可能影响这种快速升级的各种变量进行了全面的分析。首先，AGI 系统凭借无与伦比的速度以及访问和处理海量数据的能力，能够识别远远超出人类理解范围的模式和洞察。

此外，AGI 还强调研究工作的并行化。与人类研究人员不同，AGI 系统能够同时进行多项测试，并行改进其设计和性能的不同部分。

因此，这些系统将比任何人都强大得多，能够开发新技术，解决复杂的科学技术难题，甚至可能以当今无法想象的方式管理物理系统。超级智能可能带来的优势，例如材料科学、能源和健康领域的进步，这些进步可能会显著提高经济生产力和人类福祉。与此同时，控制是主要问题之一。一旦系统超越人类智力，就很难确保其行为符合人类的价值观和利益。

构建 AGI 所需的计算基础设施需要大规模工业动员，这不仅包括纯粹的算力，还包括设备效率、能源利用和信息处理能力的提升。

![](https://img.36krcdn.com/hsossms/20250830/v2_6364aa98d800419d9c5efa7a0b36a117@000000_oswg143451oswg940oswg738_img_000?x-oss-process=image/format,jpg/interlace,1)

Aschenbrenner 认为，随着 AGI 越来越近，国家安全机构将在这些技术的创造和管理中发挥更大的作用。他认为，通用人工智能的战略意义可以与阿波罗计划、曼哈顿计划相比较。

在他的文章发布一年多以后，AI 技术日新月异，不过我们也看到了当初的很多预测在被一步步得到验证。最直接的可能就是各家科技巨头纷纷投入重金，建设前所未有的大规模 AI 算力基础设施的盛景了。

那么，AGI 会如 Aschenbrenner 所说的在 2027 年到来吗？或许通过他的投资收益，我们可以间接地看到些端倪。

**参考链接：**

https://www.wsj.com/finance/investing/billions-flow-to-new-hedge-funds-focused-on-ai-related-bets-48d97f41

https://situational-awareness.ai/

https://x.com/renckorzay/status/1961480306328019407

本文来自微信公众号 [“机器之心”（ID：almosthuman2014）](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650988439&idx=1&sn=db5154549b07490a8d3862bc1708cbe0&chksm=85370ba3f9f137d8944c2f335826d1cd096502ec12bc9f5eb21e48296ff0239c956c31959d5a&scene=0&xtrack=1#rd)，作者：关注AI的，36氪经授权发布。
